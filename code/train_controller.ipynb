{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ours.encoder import TransformerEncoder, RNNEncoder, TransformerEncoderVAE\n",
    "from ours.decoder import TransformerDecoder, RNNDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = TransformerEncoderVAE(num_encoder_layers=2,\n",
    "#                                 nhead=8,\n",
    "#                                 vocab_size=7,\n",
    "#                                 embedding_size=64,\n",
    "#                                 dropout=0.1,\n",
    "#                                 activation='relu',\n",
    "#                                 dim_feedforward=256,\n",
    "#                                 batch_first=True,\n",
    "#                                 mlp_layers=1,\n",
    "#                                 mlp_hidden_size=200,\n",
    "#                                 mlp_dropout=0)\n",
    "# encoder = RNNEncoder(layers=2, vocab_size=7, hidden_size=64, dropout=0.0, mlp_layers=3, mlp_hidden_size=200, mlp_dropout=0.0)\n",
    "# decoder = RNNDecoder(layers=2, vocab_size=7, hidden_size=64, dropout=0.0, length=6, gpu=0)\n",
    "encoder = TransformerEncoder(num_encoder_layers=2,\n",
    "                             nhead=8,\n",
    "                             vocab_size=7,\n",
    "                             embedding_size=64,\n",
    "                             dropout=0.1,\n",
    "                             activation='relu',\n",
    "                             dim_feedforward=256,\n",
    "                             batch_first=True,\n",
    "                             mlp_layers=3,\n",
    "                             mlp_hidden_size=200,\n",
    "                             mlp_dropout=0)\n",
    "decoder = TransformerDecoder(num_decoder_layers=2,\n",
    "                             nhead=8,\n",
    "                             vocab_size=7,\n",
    "                             embedding_size=64,\n",
    "                             dropout=0.1,\n",
    "                             activation='relu',\n",
    "                             dim_feedforward=256,\n",
    "                             batch_first=True,\n",
    "                             length=6,\n",
    "                             gpu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = torch.tensor([[0, 1, 2, 3, 5, 5],[1, 2, 3, 4, 5, 5]], dtype=torch.long)\n",
    "encoder_target = torch.tensor([[0.91], [0.94]], dtype=torch.float32)\n",
    "decoder_input = torch.tensor([[5, 0, 1, 2, 3, 5], [5, 1, 2, 3, 4, 5]], dtype=torch.long)\n",
    "decoder_target = torch.tensor([[0, 1, 2, 3, 5, 5],[1, 2, 3, 4, 5, 5]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input.cuda(0)\n",
    "encoder_target = encoder_target.cuda(0).requires_grad_()\n",
    "decoder_input = decoder_input.cuda(0)\n",
    "decoder_target = decoder_target.cuda(0)\n",
    "encoder = encoder.cuda(0)\n",
    "decoder = decoder.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001, weight_decay=0.0)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_square_subsequent_mask() missing 1 required positional argument: 'sz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/NIPSAutoFS/code/train_controller.ipynb 单元格 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.1.3.100/root/NIPSAutoFS/code/train_controller.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m decoder_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.1.3.100/root/NIPSAutoFS/code/train_controller.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m encoder_outputs, encoder_hidden, feat_emb, predict_value, mu, logvar \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mforward(encoder_input)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.1.3.100/root/NIPSAutoFS/code/train_controller.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m decoder_outputs \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mforward_train_valid(decoder_input, encoder_outputs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.1.3.100/root/NIPSAutoFS/code/train_controller.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m _, feat \u001b[39m=\u001b[39m decoder_outputs\u001b[39m.\u001b[39mmax(\u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.1.3.100/root/NIPSAutoFS/code/train_controller.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m feat \u001b[39m=\u001b[39m feat\u001b[39m.\u001b[39mreshape(encoder_input\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), encoder_input\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/NIPSAutoFS/code/ours/decoder.py:282\u001b[0m, in \u001b[0;36mTransformerDecoder.forward_train_valid\u001b[0;34m(self, x, encoder_outputs)\u001b[0m\n\u001b[1;32m    279\u001b[0m embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositionalEncoding(embedded)\n\u001b[1;32m    281\u001b[0m \u001b[39m# construct squence mask\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m tgt_mask \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mTransformer\u001b[39m.\u001b[39;49mgenerate_square_subsequent_mask(output_size)\u001b[39m.\u001b[39mcuda(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpu)\n\u001b[1;32m    283\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(embedded, encoder_outputs, tgt_mask)\n\u001b[1;32m    285\u001b[0m \u001b[39m# out, attn = self.attention(out, encoder_outputs)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_square_subsequent_mask() missing 1 required positional argument: 'sz'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    encoder_outputs, encoder_hidden, feat_emb, predict_value, mu, logvar = encoder.forward(encoder_input)\n",
    "    decoder_outputs = decoder.forward_train_valid(decoder_input, encoder_outputs)\n",
    "    _, feat = decoder_outputs.max(2, keepdim=True)\n",
    "    feat = feat.reshape(encoder_input.size(0), encoder_input.size(1))\n",
    "    # kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    loss_1 = F.mse_loss(predict_value.squeeze(), encoder_target.squeeze())\n",
    "    loss_2 = F.nll_loss(decoder_outputs.contiguous().view(-1, decoder_outputs.size(-1)), decoder_target.view(-1))\n",
    "    loss = 0.8 * loss_1 + 0.2 * loss_2\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 5.0)\n",
    "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 5.0)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    print(loss.data, loss_1.data, loss_2.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_hidden, feat_emb, predict_value, mu, logvar = encoder.forward(encoder_input)\n",
    "decoder_outputs = decoder.forward_train_valid(decoder_input, encoder_outputs)\n",
    "_, feat = decoder_outputs.max(2, keepdim=True)\n",
    "feat = feat.reshape(encoder_input.size(0), encoder_input.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = encoder_outputs.shape[0]\n",
    "# input_id = torch.LongTensor([5] * batch_size).view(batch_size, 1).cuda(0)\n",
    "input_id = torch.tensor([[5], [5]], dtype=torch.long).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(decoder.length):\n",
    "    output_id = decoder.forward_step(encoder_outputs, input_id)\n",
    "    print(output_id)\n",
    "    input_id = torch.cat((input_id, output_id[:,-1].reshape(-1, 1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_softmax = F.log_softmax(decoder.out(out.contiguous().view(-1, decoder.embedding_size)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, next_input_id = predict_softmax.max(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input_id.reshape(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_res = []\n",
    "for step in range(decoder.length):\n",
    "    input_id = decoder.forward_step(encoder_outputs, input_id)\n",
    "    infer_res.append(input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen = torch.cat(infer_res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen_list = []\n",
    "new_gen_list.extend(new_gen.data.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_env\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"german_credit\"\n",
    "exp_name = \"transformerVae_eta_0.01\"\n",
    "choice = torch.load(\"/home/dwangyang/NIPS2023/IJCAI-AutoFS/data/history/\"+data_name+\"/generated_choice_\"+exp_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:  initialize the train and test dataset\n",
      "INFO:  Pre on original is: 0.7304, Pre on generated is: 0.7343\n",
      "INFO:  Rec on original is: 0.7312, Rec on generated is: 0.7438\n",
      "INFO:  F-1 on original is: 0.6927, F-1 on generated is: 0.7352\n",
      "INFO:  ROC/AUC on original is: 0.6229, ROC/AUC on generated is: 0.6846\n",
      "INFO:  Pre on original is: 0.7304, Pre on generated is: 0.7072\n",
      "INFO:  Rec on original is: 0.7312, Rec on generated is: 0.7188\n",
      "INFO:  F-1 on original is: 0.6927, F-1 on generated is: 0.7093\n",
      "INFO:  ROC/AUC on original is: 0.6229, ROC/AUC on generated is: 0.6564\n",
      "INFO:  Pre on original is: 0.7304, Pre on generated is: 0.7072\n",
      "INFO:  Rec on original is: 0.7312, Rec on generated is: 0.7188\n",
      "INFO:  F-1 on original is: 0.6927, F-1 on generated is: 0.7093\n",
      "INFO:  ROC/AUC on original is: 0.6229, ROC/AUC on generated is: 0.6564\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for init_seed in range(1):\n",
    "    fe = feature_env.FeatureEvaluator(data_name)\n",
    "    for i in range(choice.shape[0]):\n",
    "        res = fe.report_performance(choice[i], store=False, flag='train', init_seed=init_seed)\n",
    "        results.append((res, choice[i], i, init_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7351783625730995,\n",
       "  0.6846235231881502,\n",
       "  tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]),\n",
       "  0,\n",
       "  0),\n",
       " (0.7093421052631579,\n",
       "  0.656409804267325,\n",
       "  tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]),\n",
       "  1,\n",
       "  0),\n",
       " (0.7093421052631579,\n",
       "  0.656409804267325,\n",
       "  tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]),\n",
       "  2,\n",
       "  0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.generate_data(best_res[1], 'train').to_hdf(f'../data/history/{fe.task_name}/best-ours-test.hdf', key='train')\n",
    "fe.generate_data(best_res[1], 'test').to_hdf(f'../data/history/{fe.task_name}/best-ours-test.hdf', key='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "x = np.arange(-3.5, 3.5, 0.2)\n",
    "y = np.arange(-3.5, 3.5, 0.2)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Z = np.exp(-(X-1)**2/2 - (Y-1)**2/2) * (2 - X**2/2 - Y**2/4)\n",
    "X, Y, Z = axes3d.get_test_data()\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "surf = ax.plot_wireframe(X, Y, Z, alpha=0.5)\n",
    "# ax.contour(X, Y, Z, cmap=cm.Accent, linewidths=1.5)\n",
    "ax.set_facecolor('white')\n",
    "ax.set_axis_off()\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.tick_params(colors='None')\n",
    "\n",
    "# ax.view_init(30, 45)\n",
    "surf.set_linewidth(1)\n",
    "\n",
    "fig.set_dpi(600)\n",
    "fig.set_size_inches(10, 8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
